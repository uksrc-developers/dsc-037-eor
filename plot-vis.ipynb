{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "087e6ac2",
   "metadata": {},
   "source": [
    "# DSC-037 step 3: Assessment & Verfication \n",
    "---\n",
    "DSC-037: Cable reflection systematics for EoR science\n",
    "\n",
    "### Authors:\n",
    "SHAO EoR Group and Teal Team\n",
    "\n",
    "### Documentation on confluence:\n",
    "\n",
    "Summary: This notebook is a first implementation of DSC-037 step 3 to plot visibilities (amplitude and phase) for individual baselines to assess temporal and spectral smoothness.\n",
    "\n",
    "DSC description page: https://confluence.skatelescope.org/x/0rs6F\n",
    "Chronological walkthrough: https://confluence.skatelescope.org/x/osw6F\n",
    "Implementation: https://confluence.skatelescope.org/x/n8LMF\n",
    "GitHub repo: https://github.com/uksrc-developers/dsc-037-eor\n",
    "\n",
    "\n",
    "Ticket: TEAL-1128 https://jira.skatelescope.org/browse/TEAL-1128\n",
    "\n",
    "This notebook plots visibility amplitude/phase vs time/frequency from either:\n",
    "1. LOFAR Measurement Set (MS) format (using casacore)\n",
    "2. UVFITS or other formats (using pyuvdata)\n",
    "\n",
    "\n",
    "\n",
    "**Dependencies:** `casacore-tools`, `python-casacore`, `pyuvdata`, `numpy`, `matplotlib`, `astropy`\n",
    "\n",
    "Last updated: 2025-10-15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af91b52d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52644867",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from casacore.tables import table\n",
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "import yaml\n",
    "\n",
    "try:\n",
    "    from pyuvdata import UVData\n",
    "    PYUVDATA_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PYUVDATA_AVAILABLE = False\n",
    "    print(\"[WARNING] pyuvdata not available - UVFITS/pyuvdata-supported formats will not work\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d7f1d8",
   "metadata": {},
   "source": [
    "## Constants and Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f74ba318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "CORR_MAP_NUM2STR = {5: 'RR', 6: 'RL', 7: 'LR', 8: 'LL', 9: 'XX', 10: 'XY', 11: 'YX', 12: 'YY'}\n",
    "CORR_MAP_STR2NUM = {v: k for k, v in CORR_MAP_NUM2STR.items()}\n",
    "\n",
    "# ----------------------\n",
    "# Utilities / helpers\n",
    "# ----------------------\n",
    "def robust_nanmedian(a, axis=None):\n",
    "    \"\"\"Compute the median of an array, ignoring NaNs.\"\"\"\n",
    "    return np.nanmedian(a, axis=axis)\n",
    "\n",
    "def robust_nanmad_over_med(a, axis=None):\n",
    "    \"\"\"Robust scatter estimator (median absolute deviation / median).\"\"\"\n",
    "    med = np.nanmedian(a, axis=axis)\n",
    "    if np.ndim(med) == 0:\n",
    "        if not np.isfinite(med) or med == 0:\n",
    "            return np.nan\n",
    "    else:\n",
    "        med = np.where(med == 0, np.nan, med)\n",
    "    mad = np.nanmedian(np.abs(a - med), axis=axis)\n",
    "    return 1.4826 * mad / np.abs(med)\n",
    "\n",
    "def unwrap_safe_ms(ph, axis=-1):\n",
    "    \"\"\"Safely unwrap phase array.\"\"\"\n",
    "    ph = np.array(ph, dtype=float)\n",
    "    return np.unwrap(ph, axis=axis)\n",
    "\n",
    "def unwrap_safe_uvfits(ph):\n",
    "    ph = np.array(ph, dtype=float)\n",
    "    unwrapped = np.full_like(ph, np.nan, dtype=float)\n",
    "    mask = np.isfinite(ph)\n",
    "    if np.count_nonzero(mask) > 1:\n",
    "        unwrapped_freq = np.full_like(ph, np.nan)\n",
    "        unwrapped_freq[mask] = np.unwrap(ph[mask])\n",
    "        unwrapped = unwrapped_freq\n",
    "    else:\n",
    "        unwrapped = ph\n",
    "    return unwrapped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c375af0",
   "metadata": {},
   "source": [
    "## MS-specific Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11908d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_index_ms(ms, want_corr):\n",
    "    \"\"\"Find index of wanted correlation in POLARIZATION table (MS format).\"\"\"\n",
    "    pol = table(f\"{ms}/POLARIZATION\", readonly=True, ack=False)\n",
    "    corr_types = pol.getcol('CORR_TYPE')[0] \n",
    "    pol.close()\n",
    "    nums = list(corr_types)\n",
    "    labels = [CORR_MAP_NUM2STR.get(int(x), str(x)) for x in nums]\n",
    "    try:\n",
    "        idx = labels.index(want_corr.upper())\n",
    "    except ValueError:\n",
    "        raise RuntimeError(f\"Requested correlation {want_corr} not found in POLARIZATION row0: {labels}\")\n",
    "    return idx, labels\n",
    "\n",
    "def get_antenna_index_ms(ms, name_or_index):\n",
    "    \"\"\"Get antenna index from name or index (MS format).\"\"\"\n",
    "    ants = table(f\"{ms}/ANTENNA\", readonly=True, ack=False).getcol('NAME')\n",
    "    if str(name_or_index).isdigit():\n",
    "        idx = int(name_or_index)\n",
    "    else:\n",
    "        where = np.where(ants == name_or_index)[0]\n",
    "        if len(where) == 0:\n",
    "            raise RuntimeError(f\"Antenna {name_or_index} not found. Available antennas: {list(ants)}\")\n",
    "        idx = int(where[0])\n",
    "    return idx\n",
    "\n",
    "def get_freq_axis_ms(ms, ddid_unique):\n",
    "    \"\"\"Get frequency axis for a given DATA_DESC_ID (MS format).\"\"\"\n",
    "    dd = table(f\"{ms}/DATA_DESCRIPTION\", readonly=True, ack=False)\n",
    "    spw_id = int(dd.getcell('SPECTRAL_WINDOW_ID', ddid_unique))\n",
    "    dd.close()\n",
    "    spw = table(f\"{ms}/SPECTRAL_WINDOW\", readonly=True, ack=False)\n",
    "    chan_freq = spw.getcell('CHAN_FREQ', spw_id)  # Hz shape [nchan]\n",
    "    spw.close()\n",
    "    return chan_freq * 1e-6  # MHz\n",
    "\n",
    "def ensure_single_ddid_ms(sel):\n",
    "    \"\"\"Ensure selection contains only one DATA_DESC_ID (MS format).\"\"\"\n",
    "    ddids = sel.getcol('DATA_DESC_ID')\n",
    "    uniq = np.unique(ddids)\n",
    "    if uniq.size != 1:\n",
    "        raise RuntimeError(f\"Selection contains multiple DATA_DESC_IDs: {uniq}. Please refine your selection.\")\n",
    "    return int(uniq[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351e7742",
   "metadata": {},
   "source": [
    "## UVFITS/pyuvdata-specific Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1374b5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pol_index_uv(uv, want_pol):\n",
    "    \"\"\"Map polarization string to index (UVFITS/pyuvdata format).\"\"\"\n",
    "    want = want_pol.upper()\n",
    "    \n",
    "    # First, try to get available polarizations for debugging\n",
    "    available_pols = []\n",
    "    try:\n",
    "        if hasattr(uv, \"get_pols\"):\n",
    "            available_pols = uv.get_pols()\n",
    "            print(f\"[DEBUG] Available polarizations from get_pols(): {available_pols}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[DEBUG] Could not get polarizations from get_pols(): {e}\")\n",
    "    \n",
    "    # Try pol_string_array if available\n",
    "    if hasattr(uv, \"polarization_array\"):\n",
    "        try:\n",
    "            pol_strings = uv.get_pols()\n",
    "            print(f\"[DEBUG] Polarization strings from get_pols(): {pol_strings}\")\n",
    "            for idx, ps in enumerate(pol_strings):\n",
    "                if ps.upper() == want:\n",
    "                    return idx, pol_strings\n",
    "        except Exception as e:\n",
    "            print(f\"[DEBUG] Exception in get_pols(): {e}\")\n",
    "    \n",
    "    # Fallback: try polarization_array directly\n",
    "    if hasattr(uv, \"polarization_array\"):\n",
    "        pols = uv.polarization_array\n",
    "        print(f\"[DEBUG] polarization_array: {pols}\")\n",
    "        if len(pols) > 0 and isinstance(pols[0], str):\n",
    "            pol_strings = list(pols)\n",
    "            print(f\"[DEBUG] String polarizations: {pol_strings}\")\n",
    "            if want in pol_strings:\n",
    "                return pol_strings.index(want), pol_strings\n",
    "        else:\n",
    "            # Try numeric mapping\n",
    "            common = {'XX': -5, 'YY': -6, 'XY': -7, 'YX': -8}\n",
    "            print(f\"[DEBUG] Trying numeric mapping for '{want}'\")\n",
    "            if want in common:\n",
    "                num = common[want]\n",
    "                print(f\"[DEBUG] Looking for numeric value {num} in {pols}\")\n",
    "                if num in pols:\n",
    "                    return list(pols).index(num), [str(p) for p in pols]\n",
    "    \n",
    "    # Try alternative methods\n",
    "    try:\n",
    "        if hasattr(uv, \"pol_string_array\"):\n",
    "            pol_strings = uv.pol_string_array\n",
    "            print(f\"[DEBUG] pol_string_array: {pol_strings}\")\n",
    "            if want in pol_strings:\n",
    "                return list(pol_strings).index(want), list(pol_strings)\n",
    "    except Exception as e:\n",
    "        print(f\"[DEBUG] Exception with pol_string_array: {e}\")\n",
    "    \n",
    "    # Enhanced error message\n",
    "    error_msg = f\"Could not map requested polarization '{want}' to data polarizations.\"\n",
    "    if available_pols:\n",
    "        error_msg += f\" Available polarizations: {available_pols}\"\n",
    "    else:\n",
    "        error_msg += \" Could not determine available polarizations.\"\n",
    "    \n",
    "    raise RuntimeError(error_msg)\n",
    "\n",
    "def antenna_name_to_index_uv(uv, name_or_index):\n",
    "    \"\"\"Convert antenna name or index to antenna index (UVFITS/pyuvdata format).\"\"\"\n",
    "    try:\n",
    "        index = int(name_or_index)\n",
    "        if hasattr(uv, \"Nants_telescope\") and index >= uv.Nants_telescope:\n",
    "            print(f\"[WARNING] Antenna index {index} may be out of range (Nants_telescope={uv.Nants_telescope})\")\n",
    "        return index\n",
    "    except (ValueError, TypeError):\n",
    "        pass\n",
    "    \n",
    "    if hasattr(uv, \"antenna_names\"):\n",
    "        names = np.array(uv.antenna_names)\n",
    "        where = np.where(names == name_or_index)[0]\n",
    "        if where.size == 0:\n",
    "            available_names = list(names[:min(20, len(names))])\n",
    "            raise RuntimeError(f\"Antenna name '{name_or_index}' not found. Available: {available_names} ...\")\n",
    "        return int(where[0])\n",
    "    else:\n",
    "        # If no antenna_names attribute, assume name_or_index is already an index\n",
    "        try:\n",
    "            return int(name_or_index)\n",
    "        except (ValueError, TypeError):\n",
    "            raise RuntimeError(f\"UVData has no 'antenna_names' attribute and '{name_or_index}' is not a valid antenna index.\")\n",
    "\n",
    "def freq_axis_uv(uv):\n",
    "    \"\"\"Return frequency axis in MHz (UVFITS/pyuvdata format).\"\"\"\n",
    "    fa = uv.freq_array\n",
    "    if fa is None:\n",
    "        raise RuntimeError(\"UVData has no freq_array\")\n",
    "    fa = np.array(fa)\n",
    "    if fa.ndim == 2:\n",
    "        if fa.shape[0] == 1:\n",
    "            freqs = fa[0]\n",
    "        else:\n",
    "            freqs = fa.flatten()\n",
    "    else:\n",
    "        freqs = fa\n",
    "    return freqs * 1e-6  # Hz -> MHz\n",
    "\n",
    "def select_baseline_uv(uv, ant1, ant2):\n",
    "    \"\"\"Select baseline indices (UVFITS/pyuvdata format).\"\"\"\n",
    "    a1 = int(ant1)\n",
    "    a2 = int(ant2)\n",
    "    ant1_arr = uv.ant_1_array\n",
    "    ant2_arr = uv.ant_2_array\n",
    "    mask = ((ant1_arr == a1) & (ant2_arr == a2)) | ((ant1_arr == a2) & (ant2_arr == a1))\n",
    "    blt_inds = np.where(mask)[0]\n",
    "    if blt_inds.size == 0:\n",
    "        raise RuntimeError(f\"No baseline found for antenna pair {a1}-{a2}.\")\n",
    "    return blt_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7eaa078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_uvdata_polarizations(uv):\n",
    "    \"\"\"Inspect and print information about polarizations in UVData object.\"\"\"\n",
    "    print(\"=== UVData Polarization Inspection ===\")\n",
    "    \n",
    "    # Check various polarization attributes\n",
    "    attrs_to_check = [\n",
    "        'polarization_array', 'pol_string_array', 'Npols', 'polarization_array'\n",
    "    ]\n",
    "    \n",
    "    for attr in attrs_to_check:\n",
    "        if hasattr(uv, attr):\n",
    "            try:\n",
    "                value = getattr(uv, attr)\n",
    "                print(f\"{attr}: {value}\")\n",
    "            except Exception as e:\n",
    "                print(f\"{attr}: Error accessing - {e}\")\n",
    "        else:\n",
    "            print(f\"{attr}: Not available\")\n",
    "    \n",
    "    # Try get_pols method\n",
    "    try:\n",
    "        pols = uv.get_pols()\n",
    "        print(f\"get_pols(): {pols}\")\n",
    "    except Exception as e:\n",
    "        print(f\"get_pols(): Error - {e}\")\n",
    "    \n",
    "    # Try to understand the data structure\n",
    "    try:\n",
    "        if hasattr(uv, 'data_array'):\n",
    "            print(f\"data_array shape: {uv.data_array.shape}\")\n",
    "        if hasattr(uv, 'Npols'):\n",
    "            print(f\"Npols: {uv.Npols}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing data structure: {e}\")\n",
    "    \n",
    "    print(\"=== End Inspection ===\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2c8a43",
   "metadata": {},
   "source": [
    "## Core Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a9b3f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved process_uvfits function with better debugging\n",
    "def process_uvfits_improved(uvfits_path, ant1, ant2, pol, col, timebin, chanbin, use_weights):\n",
    "    \"\"\"Process UVFITS format data using pyuvdata with enhanced debugging.\"\"\"\n",
    "    if not PYUVDATA_AVAILABLE:\n",
    "        raise RuntimeError(\"pyuvdata is required for UVFITS processing but not available\")\n",
    "    \n",
    "    uv = UVData.from_file(uvfits_path)\n",
    "    \n",
    "    # Inspect polarizations for debugging\n",
    "    inspect_uvdata_polarizations(uv)\n",
    "    \n",
    "    # Map antenna names/indices\n",
    "    a1_idx = antenna_name_to_index_uv(uv, ant1)\n",
    "    a2_idx = antenna_name_to_index_uv(uv, ant2)\n",
    "    \n",
    "    # Map polarization with enhanced error handling\n",
    "    try:\n",
    "        pol_idx, pol_list = find_pol_index_uv(uv, pol)\n",
    "        print(f\"[INFO] Successfully mapped polarization '{pol}' to index {pol_idx}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Polarization mapping failed: {e}\")\n",
    "        print(f\"[INFO] Available polarizations: {pol_list if 'pol_list' in locals() else 'Could not determine'}\")\n",
    "        raise\n",
    "    \n",
    "    # Get frequency axis\n",
    "    freq_mhz = freq_axis_uv(uv)\n",
    "    \n",
    "    # Extract data\n",
    "    weight = None\n",
    "    \n",
    "    if use_weights:\n",
    "        if hasattr(uv, \"weight_array\"):\n",
    "            weight = uv.weight_array\n",
    "        elif hasattr(uv, \"WEIGHT_SPECTRUM\"):\n",
    "            weight = uv.WEIGHT_SPECTRUM\n",
    "    \n",
    "    # Select baseline and pol\n",
    "    v = uv.get_data((a1_idx, a2_idx, uv.polarization_array[pol_idx]))\n",
    "    f = uv.get_flags((a1_idx, a2_idx, uv.polarization_array[pol_idx]))\n",
    "    w = uv.nsample_array\n",
    "    \n",
    "    # Channel binning\n",
    "    if chanbin > 1:\n",
    "        nchan = v.shape[1]\n",
    "        new_nchan = (nchan // chanbin) * chanbin\n",
    "        if new_nchan < chanbin:\n",
    "            raise RuntimeError(\"chanbin too large for available channels\")\n",
    "        v = v[:, :new_nchan].reshape(v.shape[0], -1, chanbin).mean(axis=2)\n",
    "        f = f[:, :new_nchan].reshape(f.shape[0], -1, chanbin).any(axis=2)\n",
    "        w = w[:, :new_nchan].reshape(w.shape[0], -1, chanbin).mean(axis=2)\n",
    "    \n",
    "    # Mask flagged data\n",
    "    v_masked = np.where(~f, v, np.nan + 1j*np.nan)\n",
    "    \n",
    "    # Compute amplitude and phase per time\n",
    "    amp_row = np.nanmedian(np.abs(v_masked), axis=1)\n",
    "    phs_row = np.nanmedian(np.angle(v_masked), axis=1)\n",
    "    \n",
    "    # Time binning\n",
    "    times_sel = Time(uv.get_times((a1_idx, a2_idx, uv.polarization_array[pol_idx])), format=\"jd\").unix\n",
    "    if timebin > 1:\n",
    "        k = (amp_row.shape[0] // timebin) * timebin\n",
    "        if k > 0:\n",
    "            amp_row = amp_row[:k].reshape(-1, timebin).mean(axis=1)\n",
    "            phs_row = phs_row[:k].reshape(-1, timebin).mean(axis=1)\n",
    "            times_sel = times_sel[:k].reshape(-1, timebin).mean(axis=1)\n",
    "    \n",
    "    # Frequency averages\n",
    "    if use_weights and weight is not None:\n",
    "        amp_sum = np.nansum(np.abs(v_masked) * w, axis=0)\n",
    "        wsum = np.nansum(w, axis=0)\n",
    "        amp_freq = amp_sum / np.where(wsum > 0, wsum, np.nan)\n",
    "        \n",
    "        unit = v_masked / np.abs(v_masked)\n",
    "        unit[~np.isfinite(unit.real)] = np.nan + 1j*np.nan\n",
    "        phs_vec_sum = np.nansum(unit * w, axis=0)\n",
    "        phs_wsum = np.nansum(w, axis=0)\n",
    "        phs_freq = np.angle(phs_vec_sum / np.where(phs_wsum > 0, phs_wsum, np.nan))\n",
    "    else:\n",
    "        amp_freq = np.nanmean(np.abs(v_masked), axis=0)\n",
    "        unit = v_masked / np.abs(v_masked)\n",
    "        unit[~np.isfinite(unit.real)] = np.nan + 1j*np.nan\n",
    "        phs_vec_sum = np.nansum(unit, axis=0)\n",
    "        phs_wsum = np.sum(np.isfinite(unit.real), axis=0)\n",
    "        phs_freq = np.angle(phs_vec_sum / np.where(phs_wsum > 0, phs_wsum, np.nan))\n",
    "    \n",
    "    # Unwrap phases\n",
    "    phs_time_un = unwrap_safe_uvfits(phs_row)\n",
    "    phs_freq_un = unwrap_safe_uvfits(phs_freq)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    amp_time_scatter = robust_nanmad_over_med(amp_row)\n",
    "    phs_time_rms = np.nanstd(phs_time_un)\n",
    "    amp_freq_scatter = robust_nanmad_over_med(amp_freq)\n",
    "    \n",
    "    # Linear detrend phase vs freq\n",
    "    finite_mask = np.isfinite(phs_freq_un)\n",
    "    if np.count_nonzero(finite_mask) > 2:\n",
    "        freq_valid = freq_mhz[finite_mask]\n",
    "        phs_valid = phs_freq_un[finite_mask]\n",
    "        A = np.vstack([freq_valid, np.ones_like(freq_valid)]).T\n",
    "        coeff, _, _, _ = np.linalg.lstsq(A, phs_valid, rcond=None)\n",
    "        phs_fit = A @ coeff\n",
    "        phs_resid = phs_valid - phs_fit\n",
    "        phs_freq_rms = np.nanstd(phs_resid)\n",
    "    else:\n",
    "        phs_freq_rms = np.nan\n",
    "    \n",
    "    t0 = np.nanmin(times_sel)\n",
    "    time_hr = (times_sel - t0) / 3600.0\n",
    "    \n",
    "    return {\n",
    "        'times': times_sel,\n",
    "        'time_hr': time_hr,\n",
    "        'amp_time': amp_row,\n",
    "        'phs_time': phs_time_un,\n",
    "        'amp_freq': amp_freq,\n",
    "        'phs_freq': phs_freq_un,\n",
    "        'freq_mhz': freq_mhz,\n",
    "        'ant1_name': uv.antenna_names[a1_idx].strip(),\n",
    "        'ant2_name': uv.antenna_names[a2_idx].strip(),\n",
    "        'corr': pol,\n",
    "        'col': col,\n",
    "        'amp_time_scatter': amp_time_scatter,\n",
    "        'phs_time_rms': phs_time_rms,\n",
    "        'amp_freq_scatter': amp_freq_scatter,\n",
    "        'phs_freq_rms': phs_freq_rms\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a70e9aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ms(ms_path, ant1, ant2, corr, col, timebin, chanbin, use_weights, chunksize):\n",
    "    \"\"\"Process MS format data.\"\"\"\n",
    "    ms = ms_path\n",
    "    a1 = get_antenna_index_ms(ms, ant1)\n",
    "    a2 = get_antenna_index_ms(ms, ant2)\n",
    "    a_lo, a_hi = (a1, a2) if a1 < a2 else (a2, a1)\n",
    "    \n",
    "    ant_names = table(f\"{ms}/ANTENNA\", readonly=True, ack=False).getcol('NAME')\n",
    "    ant1_name, ant2_name = ant_names[a_lo], ant_names[a_hi]\n",
    "    \n",
    "    corr_idx, corr_labels = get_corr_index_ms(ms, corr)\n",
    "    print(f\"[INFO] Using correlation {corr} (index {corr_idx}) from available: {corr_labels}\")\n",
    "    \n",
    "    t = table(ms, readonly=True, ack=False)\n",
    "    q = t.query(f\"ANTENNA1=={a_lo} && ANTENNA2=={a_hi}\")\n",
    "    nrows = q.nrows()\n",
    "    if nrows == 0:\n",
    "        q.close()\n",
    "        t.close()\n",
    "        raise RuntimeError(f\"No data found for antenna pair {ant1_name} ({a_lo}), {ant2_name} ({a_hi})\")\n",
    "    print(f\"[INFO] Found {nrows} rows for antenna pair {ant1_name} ({a_lo}), {ant2_name} ({a_hi})\")\n",
    "    \n",
    "    ddid = ensure_single_ddid_ms(q)\n",
    "    freq_mhz = get_freq_axis_ms(ms, ddid)\n",
    "    nchan = freq_mhz.size\n",
    "    \n",
    "    times_all = []\n",
    "    amp_time = []\n",
    "    phs_time = []\n",
    "    amp_sum = np.zeros(nchan, dtype=float)\n",
    "    amp_wsum = np.zeros(nchan, dtype=float)\n",
    "    phs_vec_sum = np.zeros(nchan, dtype=complex)\n",
    "    phs_wsum = np.zeros(nchan, dtype=float)\n",
    "    \n",
    "    have_flags = 'FLAG' in t.colnames()\n",
    "    have_ws = 'WEIGHT_SPECTRUM' in t.colnames() and use_weights\n",
    "    \n",
    "    step = chunksize\n",
    "    for start in range(0, nrows, step):\n",
    "        nr = min(step, nrows - start)\n",
    "        data = q.getcol(col, startrow=start, nrow=nr)  # shape [nr,nchan,ncorr]\n",
    "        times = q.getcol('TIME', startrow=start, nrow=nr)  # shape [nr]\n",
    "        flags = q.getcol('FLAG', startrow=start, nrow=nr) if have_flags else np.zeros(data.shape, dtype=bool)\n",
    "        \n",
    "        if data.ndim != 3 or data.shape[2] <= corr_idx:\n",
    "            q.close()\n",
    "            t.close()\n",
    "            raise RuntimeError(f\"Data column {col} has unexpected shape {data.shape} (need ncorr > {corr_idx})\")\n",
    "        \n",
    "        v = data[:, :, corr_idx]\n",
    "        f = flags[:, :, corr_idx] if flags.ndim == 3 else flags\n",
    "        \n",
    "        if chanbin > 1:\n",
    "            new_nchan = (v.shape[1] // chanbin) * chanbin\n",
    "            v = v[:, :new_nchan]\n",
    "            f = f[:, :new_nchan]\n",
    "            v = v.reshape(v.shape[0], -1, chanbin).mean(axis=2)\n",
    "            f = f.reshape(f.shape[0], -1, chanbin).any(axis=2)\n",
    "        \n",
    "        v = np.where(~f, v, np.nan + 1j*np.nan)\n",
    "        \n",
    "        amp_row = np.nanmedian(np.abs(v), axis=1)\n",
    "        phs_row = np.nanmedian(np.angle(v), axis=1)\n",
    "        \n",
    "        if timebin > 1:\n",
    "            k = (amp_row.shape[0] // timebin) * timebin\n",
    "            if k > 0:\n",
    "                amp_row = amp_row[:k].reshape(-1, timebin).mean(axis=1)\n",
    "                phs_row = phs_row[:k].reshape(-1, timebin).mean(axis=1)\n",
    "                times = times[:k].reshape(-1, timebin).mean(axis=1)\n",
    "        \n",
    "        times_all.append(times)\n",
    "        amp_time.append(amp_row)\n",
    "        phs_time.append(phs_row)\n",
    "        \n",
    "        amp_chunk = np.abs(v)\n",
    "        if have_ws:\n",
    "            ws = q.getcol('WEIGHT_SPECTRUM', startrow=start, nrow=nr)[:, :, corr_idx]\n",
    "            ws = np.where(np.isfinite(amp_chunk), ws, 0.0)\n",
    "            amp_sum += np.nansum(amp_chunk * ws, axis=0)\n",
    "            amp_wsum += np.nansum(ws, axis=0)\n",
    "        else:\n",
    "            valid = np.isfinite(amp_chunk)\n",
    "            amp_sum += np.nansum(np.where(valid, amp_chunk, 0.0), axis=0)\n",
    "            amp_wsum += np.sum(valid, axis=0)\n",
    "        \n",
    "        with np.errstate(invalid='ignore', divide='ignore'):\n",
    "            unit = v / np.abs(v)\n",
    "        unit[~np.isfinite(unit)] = np.nan + 1j*np.nan\n",
    "        if have_ws:\n",
    "            ws = q.getcol('WEIGHT_SPECTRUM', startrow=start, nrow=nr)[:, :, corr_idx]\n",
    "            ws = np.where(np.isfinite(unit.real), ws, 0.0)\n",
    "            phs_vec_sum += np.nansum(unit * ws, axis=0)\n",
    "            phs_wsum += np.nansum(ws, axis=0)\n",
    "        else:\n",
    "            valid_u = np.isfinite(unit.real)\n",
    "            phs_vec_sum += np.nansum(np.where(valid_u, unit, 0.0), axis=0)\n",
    "            phs_wsum += np.sum(valid_u, axis=0)\n",
    "    \n",
    "    q.close()\n",
    "    t.close()\n",
    "    \n",
    "    times_all = np.concatenate(times_all)\n",
    "    amp_time = np.concatenate(amp_time)\n",
    "    phs_time = np.concatenate(phs_time)\n",
    "    phs_time = unwrap_safe_ms(phs_time, axis=0)\n",
    "    \n",
    "    t0 = np.nanmin(times_all)\n",
    "    time_hr = (times_all - t0) / 3600.0\n",
    "    \n",
    "    amp_freq = amp_sum / np.where(amp_wsum > 0, amp_wsum, np.nan)\n",
    "    phs_freq = np.angle(phs_vec_sum / np.where(phs_wsum > 0, phs_wsum, np.nan))\n",
    "    phs_freq = unwrap_safe_ms(phs_freq, axis=0)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    amp_time_scatter = robust_nanmad_over_med(amp_time)\n",
    "    phs_time_rms = np.nanstd(phs_time)\n",
    "    amp_freq_scatter = robust_nanmad_over_med(amp_freq)\n",
    "    \n",
    "    if np.all(np.isfinite(phs_freq)):\n",
    "        A = np.vstack([freq_mhz, np.ones_like(freq_mhz)]).T\n",
    "        coeff, _, _, _ = np.linalg.lstsq(A, phs_freq, rcond=None)\n",
    "        phs_fit = A @ coeff\n",
    "        phs_resid = phs_freq - phs_fit\n",
    "        phs_freq_rms = np.nanstd(phs_resid)\n",
    "    else:\n",
    "        phs_freq_rms = np.nan\n",
    "    \n",
    "    return {\n",
    "        'times': times_all,\n",
    "        'time_hr': time_hr,\n",
    "        'amp_time': amp_time,\n",
    "        'phs_time': phs_time,\n",
    "        'amp_freq': amp_freq,\n",
    "        'phs_freq': phs_freq,\n",
    "        'freq_mhz': freq_mhz,\n",
    "        'ant1_name': ant1_name,\n",
    "        'ant2_name': ant2_name,\n",
    "        'corr': corr,\n",
    "        'col': col,\n",
    "        'amp_time_scatter': amp_time_scatter,\n",
    "        'phs_time_rms': phs_time_rms,\n",
    "        'amp_freq_scatter': amp_freq_scatter,\n",
    "        'phs_freq_rms': phs_freq_rms\n",
    "    }\n",
    "\n",
    "def process_uvfits(uvfits_path, ant1, ant2, pol, col, timebin, chanbin, use_weights):\n",
    "    \"\"\"Process UVFITS format data using pyuvdata.\"\"\"\n",
    "    if not PYUVDATA_AVAILABLE:\n",
    "        raise RuntimeError(\"pyuvdata is required for UVFITS processing but not available\")\n",
    "    \n",
    "    # uv = UVData()\n",
    "    # uv.read(uvfits_path, read_data=True)\n",
    "    uv = UVData.from_file(uvfits_path)\n",
    "    \n",
    "    # Map antenna names/indices\n",
    "    a1_idx = antenna_name_to_index_uv(uv, ant1)\n",
    "    a2_idx = antenna_name_to_index_uv(uv, ant2)\n",
    "    \n",
    "    # # Select baseline\n",
    "    # blt_inds = select_baseline_uv(uv, a1_idx, a2_idx)\n",
    "    \n",
    "    # Map polarization\n",
    "    pol_idx, _ = find_pol_index_uv(uv, pol) # pol_list\n",
    "    \n",
    "    # Get frequency axis\n",
    "    freq_mhz = freq_axis_uv(uv)\n",
    "    \n",
    "    # Extract data\n",
    "    weight = None\n",
    "    # data = uv.data_array\n",
    "    # flag = getattr(uv, \"flag_array\", None)\n",
    "    # times = uv.time_array\n",
    "    \n",
    "    if use_weights:\n",
    "        if hasattr(uv, \"weight_array\"):\n",
    "            weight = uv.weight_array\n",
    "        elif hasattr(uv, \"WEIGHT_SPECTRUM\"):\n",
    "            weight = uv.WEIGHT_SPECTRUM\n",
    "    \n",
    "    # Select baseline and pol\n",
    "    v = uv.get_data((a1_idx, a2_idx, uv.polarization_array[pol_idx]))\n",
    "    f = uv.get_flags((a1_idx, a2_idx, uv.polarization_array[pol_idx]))\n",
    "    # NEED TO BE CHECKED!\n",
    "    w = np.ones_like(v)\n",
    "    # v = data[blt_inds, :, pol_idx]\n",
    "    # f = flag[blt_inds, :, pol_idx] if flag is not None else np.zeros_like(v, dtype=bool)\n",
    "    # w = weight[blt_inds, :, pol_idx] if (weight is not None and weight.shape == data.shape) else np.ones_like(v)\n",
    "    \n",
    "    # Channel binning\n",
    "    if chanbin > 1:\n",
    "        nchan = v.shape[1]\n",
    "        new_nchan = (nchan // chanbin) * chanbin\n",
    "        if new_nchan < chanbin:\n",
    "            raise RuntimeError(\"chanbin too large for available channels\")\n",
    "        v = v[:, :new_nchan].reshape(v.shape[0], -1, chanbin).mean(axis=2)\n",
    "        f = f[:, :new_nchan].reshape(f.shape[0], -1, chanbin).any(axis=2)\n",
    "        w = w[:, :new_nchan].reshape(w.shape[0], -1, chanbin).mean(axis=2)\n",
    "    \n",
    "    # Mask flagged data\n",
    "    v_masked = np.where(~f, v, np.nan + 1j*np.nan)\n",
    "    \n",
    "    # Compute amplitude and phase per time\n",
    "    amp_row = np.nanmedian(np.abs(v_masked), axis=1)\n",
    "    phs_row = np.nanmedian(np.angle(v_masked), axis=1)\n",
    "    \n",
    "    # Time binning\n",
    "    times_sel = Time(uv.get_times((a1_idx, a2_idx, uv.polarization_array[pol_idx])), format=\"jd\").unix\n",
    "    # times_sel = times[blt_inds]\n",
    "    if timebin > 1:\n",
    "        k = (amp_row.shape[0] // timebin) * timebin\n",
    "        if k > 0:\n",
    "            amp_row = amp_row[:k].reshape(-1, timebin).mean(axis=1)\n",
    "            phs_row = phs_row[:k].reshape(-1, timebin).mean(axis=1)\n",
    "            times_sel = times_sel[:k].reshape(-1, timebin).mean(axis=1)\n",
    "    \n",
    "    # Frequency averages\n",
    "    if use_weights and weight is not None:\n",
    "        amp_sum = np.nansum(np.abs(v_masked) * w, axis=0)\n",
    "        wsum = np.nansum(w, axis=0)\n",
    "        amp_freq = amp_sum / np.where(wsum > 0, wsum, np.nan)\n",
    "        \n",
    "        unit = v_masked / np.abs(v_masked)\n",
    "        unit[~np.isfinite(unit.real)] = np.nan + 1j*np.nan\n",
    "        phs_vec_sum = np.nansum(unit * w, axis=0)\n",
    "        phs_wsum = np.nansum(w, axis=0)\n",
    "        phs_freq = np.angle(phs_vec_sum / np.where(phs_wsum > 0, phs_wsum, np.nan))\n",
    "    else:\n",
    "        amp_freq = np.nanmean(np.abs(v_masked), axis=0)\n",
    "        unit = v_masked / np.abs(v_masked)\n",
    "        unit[~np.isfinite(unit.real)] = np.nan + 1j*np.nan\n",
    "        phs_vec_sum = np.nansum(unit, axis=0)\n",
    "        phs_wsum = np.sum(np.isfinite(unit.real), axis=0)\n",
    "        phs_freq = np.angle(phs_vec_sum / np.where(phs_wsum > 0, phs_wsum, np.nan))\n",
    "    \n",
    "    # Unwrap phases\n",
    "    phs_time_un = unwrap_safe_uvfits(phs_row)\n",
    "    phs_freq_un = unwrap_safe_uvfits(phs_freq)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    amp_time_scatter = robust_nanmad_over_med(amp_row)\n",
    "    phs_time_rms = np.nanstd(phs_time_un)\n",
    "    amp_freq_scatter = robust_nanmad_over_med(amp_freq)\n",
    "    \n",
    "    # Linear detrend phase vs freq\n",
    "    finite_mask = np.isfinite(phs_freq_un)\n",
    "    if np.count_nonzero(finite_mask) > 2:\n",
    "        freq_valid = freq_mhz[finite_mask]\n",
    "        phs_valid = phs_freq_un[finite_mask]\n",
    "        A = np.vstack([freq_valid, np.ones_like(freq_valid)]).T\n",
    "        coeff, _, _, _ = np.linalg.lstsq(A, phs_valid, rcond=None)\n",
    "        phs_fit = A @ coeff\n",
    "        phs_resid = phs_valid - phs_fit\n",
    "        phs_freq_rms = np.nanstd(phs_resid)\n",
    "    else:\n",
    "        phs_freq_rms = np.nan\n",
    "    \n",
    "    t0 = np.nanmin(times_sel)\n",
    "    time_hr = (times_sel - t0) / 3600.0\n",
    "    \n",
    "    return {\n",
    "        'times': times_sel,\n",
    "        'time_hr': time_hr,\n",
    "        'amp_time': amp_row,\n",
    "        'phs_time': phs_time_un,\n",
    "        'amp_freq': amp_freq,\n",
    "        'phs_freq': phs_freq_un,\n",
    "        'freq_mhz': freq_mhz,\n",
    "        'ant1_name': uv.antenna_names[a1_idx].strip() if hasattr(uv, 'antenna_names') and uv.antenna_names is not None else f'ANT{a1_idx}',\n",
    "        'ant2_name': uv.antenna_names[a2_idx].strip() if hasattr(uv, 'antenna_names') and uv.antenna_names is not None else f'ANT{a2_idx}',\n",
    "        'corr': pol,\n",
    "        'col': col,\n",
    "        'amp_time_scatter': amp_time_scatter,\n",
    "        'phs_time_rms': phs_time_rms,\n",
    "        'amp_freq_scatter': amp_freq_scatter,\n",
    "        'phs_freq_rms': phs_freq_rms\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce8aeff",
   "metadata": {},
   "source": [
    "## Plotting Function \n",
    "\n",
    "This function is modified to `show()` the plots inline instead of saving them to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e22f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results):\n",
    "    \"\"\"Show all plots inline.\"\"\"\n",
    "    tag = f\"{results['ant1_name']}-{results['ant2_name']}_{results['corr']}_{results['col']}\"\n",
    "    \n",
    "    # Amplitude vs time\n",
    "    plt.figure()\n",
    "    plt.plot(results['time_hr'] * 3600, results['amp_time'], '.', ms=2)\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(f\"Amplitude ({tag})\")\n",
    "    plt.title(\"Amplitude vs Time\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Phase vs time\n",
    "    plt.figure()\n",
    "    plt.plot(results['time_hr'] * 3600, results['phs_time'], '.', ms=2)\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Phase (rad)\")\n",
    "    plt.title(\"Phase vs Time (unwrapped)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Amplitude vs frequency\n",
    "    plt.figure()\n",
    "    plt.plot(results['freq_mhz'], results['amp_freq'], '.', ms=2)\n",
    "    plt.xlabel(\"Frequency [MHz]\")\n",
    "    plt.ylabel(f\"Amplitude ({tag})\")\n",
    "    plt.title(\"Amplitude vs Frequency (time-avg)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Phase vs frequency\n",
    "    plt.figure()\n",
    "    plt.plot(results['freq_mhz'], results['phs_freq'], '.', ms=2)\n",
    "    plt.xlabel(\"Frequency [MHz]\")\n",
    "    plt.ylabel(\"Phase (rad)\")\n",
    "    plt.title(\"Phase vs Frequency (unwrapped, circular mean)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d2e4b1",
   "metadata": {},
   "source": [
    "# 1. Interface of Run Processing and Plotting\n",
    "\n",
    "Common parameters (input_file, ant1, ant2, corr, col, timebin, chanbin, use_weights, chunksize, format) are loaded from `config.yaml`.\n",
    "The input_file can be overridden in the cell below if needed. Run the cell to process the data and display the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78205413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_processing_and_plotting(config_file='config.yaml', input_file=None, ant1=None, ant2=None, corr=None, col=None, timebin=None, chanbin=None, use_weights=None, chunksize=None, format_type=None):\n",
    "    \"\"\"\n",
    "    Process visibility data and generate plots based on configuration parameters.\n",
    "    \n",
    "    Common parameters are read from config.yaml by default. All parameters can be overridden \n",
    "    by passing them as function arguments.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    config_file : str, optional\n",
    "        Path to configuration YAML file (default: 'config.yaml')\n",
    "    input_file : str, optional\n",
    "        Path to input data file (MS or UVFITS format). If None, read from config_file.\n",
    "    ant1 : str or int, optional\n",
    "        Antenna 1 name or index. If None, read from config_file.\n",
    "    ant2 : str or int, optional\n",
    "        Antenna 2 name or index. If None, read from config_file.\n",
    "    corr : str, optional\n",
    "        Correlation to plot (e.g. XX, XY, YY, NN, EE, NE). If None, read from config_file.\n",
    "    col : str, optional\n",
    "        Column to plot (DATA, MODEL_DATA, CORRECTED_DATA). If None, read from config_file.\n",
    "    timebin : int, optional\n",
    "        Time binning factor. If None, read from config_file.\n",
    "    chanbin : int, optional\n",
    "        Channel binning factor. If None, read from config_file.\n",
    "    use_weights : bool, optional\n",
    "        Use weights for averaging. If None, read from config_file.\n",
    "    chunksize : int, optional\n",
    "        Chunk size for MS processing. If None, read from config_file.\n",
    "    format_type : str, optional\n",
    "        Force input format ('auto', 'ms', 'uvfits'). If None, read from config_file.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Results dictionary containing processed data and statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load configuration from config.yaml\n",
    "    try:\n",
    "        with open(config_file, 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[WARNING] Config file '{config_file}' not found. Using defaults.\")\n",
    "        config = {}\n",
    "    except Exception as e:\n",
    "        print(f\"[WARNING] Error reading config file '{config_file}': {e}. Using defaults.\")\n",
    "        config = {}\n",
    "    \n",
    "    # Use config defaults if parameters not provided\n",
    "    if input_file is None:\n",
    "        input_file = config.get('input_file', '')\n",
    "        print(\"input_file: \", input_file)\n",
    "        # Fallback to notebook default if config doesn't have input_file or it's empty\n",
    "        if not input_file:\n",
    "            try:\n",
    "                input_file = INPUT_FILE\n",
    "            except NameError:\n",
    "                input_file = \"hyp_1184702048_ionosub_ssins_30l_src8k_300it_8s_80kHz_i1000.uvfits\"\n",
    "    \n",
    "    if ant1 is None:\n",
    "        ant1 = config.get('ant1', 2)\n",
    "    if ant2 is None:\n",
    "        ant2 = config.get('ant2', 6)\n",
    "    if corr is None:\n",
    "        corr = config.get('corr', 'xx')\n",
    "    if col is None:\n",
    "        col = config.get('col', 'DATA')\n",
    "    if timebin is None:\n",
    "        timebin = config.get('timebin', 1)\n",
    "    if chanbin is None:\n",
    "        chanbin = config.get('chanbin', 1)\n",
    "    if use_weights is None:\n",
    "        use_weights = config.get('use_weights', False)\n",
    "    if chunksize is None:\n",
    "        chunksize = config.get('chunksize', 100000)\n",
    "    if format_type is None:\n",
    "        format_type = config.get('format', 'auto')\n",
    "    \n",
    "    # Determine file format\n",
    "    if format_type == 'auto':\n",
    "        if input_file.endswith('.ms') or os.path.isdir(input_file):\n",
    "            # Check if it's an MS directory (has POLARIZATION subtable)\n",
    "            try:\n",
    "                with table(f\"{input_file}/POLARIZATION\", readonly=True, ack=False):\n",
    "                    file_format = 'ms'\n",
    "            except (RuntimeError, OSError):\n",
    "                # Not an MS, try UVFITS\n",
    "                try:\n",
    "                    with fits.open(input_file) as hdul:\n",
    "                        if 'PRIMARY' in hdul and 'GROUPING' in [h.name for h in hdul]:\n",
    "                            file_format = 'uvfits'\n",
    "                        else:\n",
    "                            # Try pyuvdata detection\n",
    "                            if PYUVDATA_AVAILABLE:\n",
    "                                file_format = 'uvfits'\n",
    "                            else:\n",
    "                                raise ValueError(\"Cannot determine file format and pyuvdata not available\")\n",
    "                except (OSError, KeyError):\n",
    "                    # Final attempt with pyuvdata\n",
    "                    if PYUVDATA_AVAILABLE:\n",
    "                        try:\n",
    "                            uv = UVData()\n",
    "                            uv.read(input_file, read_data=False)\n",
    "                            file_format = 'uvfits'\n",
    "                        except Exception:\n",
    "                            raise ValueError(\"Cannot determine file format\")\n",
    "                    else:\n",
    "                        raise ValueError(\"Cannot determine file format and pyuvdata not available\")\n",
    "        elif input_file.endswith(('.fits', '.uvfits', '.FITS', '.UVFITS')):\n",
    "            file_format = 'uvfits'\n",
    "        else:\n",
    "            raise ValueError(\"Cannot determine file format. Use format_type to specify.\")\n",
    "    else:\n",
    "        file_format = format_type\n",
    "\n",
    "    # Process file\n",
    "    try:\n",
    "        if file_format == 'ms':\n",
    "            print(\"[INFO] Processing as Measurement Set (MS) format\")\n",
    "            results = process_ms(\n",
    "                ms_path=input_file,\n",
    "                ant1=ant1,\n",
    "                ant2=ant2,\n",
    "                corr=corr,\n",
    "                col=col,\n",
    "                timebin=timebin,\n",
    "                chanbin=chanbin,\n",
    "                use_weights=use_weights,\n",
    "                chunksize=chunksize\n",
    "            )\n",
    "        elif file_format == 'uvfits':\n",
    "            print(\"[INFO] Processing as UVFITS format (using pyuvdata)\")\n",
    "            results = process_uvfits(\n",
    "                uvfits_path=input_file,\n",
    "                ant1=ant1,\n",
    "                ant2=ant2,\n",
    "                pol=corr,\n",
    "                col=col,\n",
    "                timebin=timebin,\n",
    "                chanbin=chanbin,\n",
    "                use_weights=use_weights\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported format: {file_format}\")\n",
    "        \n",
    "        # Print QA summary\n",
    "        print(\"\\n==== Quick QA ====\")\n",
    "        print(f\"Baseline: {results['ant1_name']}-{results['ant2_name']}  Pol: {results['corr']}  Col: {results['col']}\")\n",
    "        print(f\"Points (time): {len(results['time_hr'])}  Channels: {len(results['freq_mhz'])}\")\n",
    "        print(f\"AMP time scatter (1.4826*MAD/med): {results['amp_time_scatter']:.3f}\")\n",
    "        print(f\"PHASE time RMS (rad): {results['phs_time_rms']:.3f}\")\n",
    "        print(f\"AMP freq scatter (1.4826*MAD/med): {results['amp_freq_scatter']:.3f}\")\n",
    "        print(f\"PHASE freq RMS (rad) after linear detrend: {results['phs_freq_rms']:.3f}\")\n",
    "        print(\"===================\\n\")\n",
    "        \n",
    "        # Show plots\n",
    "        print(\"Displaying plots:\")\n",
    "        plot_results(results)\n",
    "        \n",
    "        return results\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Processing failed: {str(e)}\")\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482800f0",
   "metadata": {},
   "source": [
    "# 2. Example: Plotting Visibilities for MWA Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "446e2c8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot determine file format. Use format_type to specify.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- Execute using config.yaml and notebook parameters ---\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Common parameters from config.yaml: input_file, ant1, ant2, corr, col, timebin, chanbin, use_weights, chunksize, format\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# INPUT_FILE is set above (from config.yaml if provided, otherwise default)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# use defaults from config.yaml and notebook:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m results = \u001b[43mrun_processing_and_plotting\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconfig.yaml\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 95\u001b[39m, in \u001b[36mrun_processing_and_plotting\u001b[39m\u001b[34m(input_file, ant1, ant2, corr, col, timebin, chanbin, use_weights, chunksize, format_type)\u001b[39m\n\u001b[32m     93\u001b[39m         file_format = \u001b[33m'\u001b[39m\u001b[33muvfits\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot determine file format. Use format_type to specify.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     97\u001b[39m     file_format = format_type\n",
      "\u001b[31mValueError\u001b[39m: Cannot determine file format. Use format_type to specify."
     ]
    }
   ],
   "source": [
    "# --- Execute using config.yaml and notebook parameters ---\n",
    "# Common parameters from config.yaml: input_file, ant1, ant2, corr, col, timebin, chanbin, use_weights, chunksize, format\n",
    "# INPUT_FILE is set above (from config.yaml if provided, otherwise default)\n",
    "# To customize, edit config.yaml for common params, or modify INPUT_FILE above to override\n",
    "\n",
    "# You can override specific parameters by passing them as arguments:\n",
    "# results = run_processing_and_plotting(\n",
    "#     input_file=\"your_file.uvfits\",\n",
    "#     ant1=2,\n",
    "#     ant2=6,\n",
    "#     corr=\"xx\"\n",
    "# )\n",
    "\n",
    "\n",
    "# use defaults from config.yaml and notebook:\n",
    "results = run_processing_and_plotting('config.yaml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
